<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Omal Perera</title>
		<description>Omal Perera</description>
		<link>/</link>
		<atom:link href="/feed.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>kerberos Simplified</title>
				<description>&lt;p&gt;Hello all of you! lets discuss what is kerberos in a simple manner. This article is not going into a deep level of kerberos technology. But you all can get a highlevel overview, with regards to its History, how it works, why is it needed, advantages as well as disadvantages etc.
&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Kerberos is a popular &lt;strong&gt;authentication protocol&lt;/strong&gt; that can be used for single sign-on (SSO). The main key concept behind SSO is getting the services that a user is authorized, with a single login (one time activity). So, user don’t want to login on each of those services in many different times. Kerberos systems offers protection against many network attacks and vulnerabilities. Following are some characteristics of Kerberos.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;uses tickets to authenticate&lt;/li&gt;
  &lt;li&gt;avoids saving passwords locally&lt;/li&gt;
  &lt;li&gt;avoids sending passwords over the internet&lt;/li&gt;
  &lt;li&gt;involves a trusted 3rd-party&lt;/li&gt;
  &lt;li&gt;built on symmetric-key cryptography&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;history&quot;&gt;History&lt;/h2&gt;

&lt;p&gt;Initially, Massachusetts Institute of Technology (MIT) developed Kerberos to protect network services provided by Project Athena in 1980. The current version of the protocol is version 5. Previous versions of the protocol were based on the earlier Needham–Schroeder symmetric key protocol. Version 4 of the Kerberos protocol was the first version that was publicly released, and is now deprecated for security reasons. In 1987, MIT released the Kerberos software freely available, under a certain copyright permissions and in 2007, MIT formed the Kerberos Consortium to encourage development. In 1993, It became an IETF Standard which is the premier Internet standard.&lt;/p&gt;

&lt;p&gt;The name Kerberos arrived from the three-headed dog that guarded the entrance to Hades in Greek mythology. It’s pretty matching for the Kerberos concept since it takes a third-party (a Key Distribution Center) to authenticate between a client and a service or host machine.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;why-kerberos&quot;&gt;Why Kerberos&lt;/h2&gt;

&lt;p&gt;Kerberos has two basic purposes namely &lt;strong&gt;security&lt;/strong&gt; and &lt;strong&gt;authentication&lt;/strong&gt;. On non-distributed computer systems, a secret key or a password can be used to prove a user’s identity. But on a distributed computer network system, scenario is different than standalone computer systems. If same theory applied for the distributed systems, password must be transmitted over the network, from one machine to another machine. For an example if a user requests a private file from a server, that typical user needs to send his secret key to the server in order to authenticate him. Because this password is the one secret piece of information that identifies a user, anyone in that network knowing a user’s password can access their files as that user.&lt;/p&gt;

&lt;p&gt;Therefore, it is necessary to prevent anyone from intercepting or eavesdropping on the transmitted password. In addition, it is necessary to provide a means of authenticating users any time a user requests a service, they must prove their identity.&lt;/p&gt;

&lt;p&gt;In order to fill above mentioned gap in the security in distributed systems, Kerberos has:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Strong mutual authentication.
    &lt;ul&gt;
      &lt;li&gt;Secrets are not transmitted across the network.&lt;/li&gt;
      &lt;li&gt;Critical authentication data is encrypted.&lt;/li&gt;
      &lt;li&gt;The client (user) is authenticated to the server and the server is authenticated to the client. The client identity is used to authorize services on the server.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Single sign-on.
    &lt;ul&gt;
      &lt;li&gt;A user convenience meaning a single identity and password can be used for many services with only one login sequence.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;so-what-is-the-different-between-firewall--kerberos&quot;&gt;So what is the different between Firewall &amp;amp; Kerberos&lt;/h2&gt;

&lt;p&gt;A firewall is a kind of network security system. Firewalls can be presents in either hardware or software based. Those are basically depending on rules that controls incoming and outgoing network traffic. A firewall acts as a barrier between a trusted network and untrusted network and controls access to the resources of a network through a positive control model. Firewalls assumes, that the attackers are coming from the outside. But in distributed systems, attacks are frequently from within the system.&lt;/p&gt;

&lt;p&gt;In contrast, Kerberos assumes that network connections are the weak link in network security rather than servers and work stations.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;kerberos-components&quot;&gt;Kerberos Components&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Key Distribution Center (KDC)&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Each Kerberos realm will have at least one Kerberos server. This server, the Key Distribution Center, contains the Authentication Service, the Ticket-Granting Service, and the master database for Kerberos. These services are implemented as a single daemon.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Authentication Service&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;The authentication service handles user authentication, or the process of verifying that principals are correctly identified.&lt;/li&gt;
      &lt;li&gt;Consists of the security servers in the KDC (or KDCs), and security clients.&lt;/li&gt;
      &lt;li&gt;A security client communicates with a security server to request information and operations. The security server accesses the registry database to perform queries and updates and to validate user logins.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ticket-Granting Service&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Once authenticated, a principal will be granted a TGT and a ticket session key, which gives the principal the right to use the ticket. This combination of the ticket and its associated key is known as your credentials.&lt;/li&gt;
      &lt;li&gt;A principal’s credentials are stored in a credentials cache, which is often just a file in the principal’s local directory tree.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The Kerberos Database&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;The Kerberos database contains all of the realm’s Kerberos principals, their passwords, and other administrative information about each principal.&lt;/li&gt;
      &lt;li&gt;Each KDC contains its own copy of the Kerberos database. The master KDC contains the primary copy of the database, which it propagates at regular intervals to the slave KDCs.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Kerberos Utility Programs&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;OpenVMS provides three different versions of each of the Kerberos user interface programs, the original UNIX style, a DCL version, and an X Windows version.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Kerberos Registry&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;The Kerberos registry can be manipulated in several ways. It is initially created
via the KRB$CONFIGURE command procedure. Other tools used to access the Kerberos information are:&lt;/li&gt;
    &lt;/ul&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;kadmin&lt;/code&gt; - Used for reading or updating the Kerberos registry.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;kinit&lt;/code&gt; - Creates credentials for a user.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;klist&lt;/code&gt; - Displays the existing credentials for a user.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;kdestroy&lt;/code&gt; - Deletes a user’s credentials.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;kpasswd&lt;/code&gt; - Changes a user’s Kerberos password.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;kdb5_util&lt;/code&gt; - Dumps or loads the Kerberos database for save and restore operations.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;authenticating-using-kerberos&quot;&gt;Authenticating using Kerberos&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;/images/kerberos-auth-omalperera.github.io&quot; alt=&quot;Authentication mechanisam&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;When a client logs in to the realm, an authentication request is sent to the Kerberos Key Distribution Center (KDC).&lt;/li&gt;
  &lt;li&gt;A Ticket-Granting Ticket (TGT) is returned as the result of authentication.&lt;/li&gt;
  &lt;li&gt;When the client application starts, the TGT is used to request an application ticket.&lt;/li&gt;
  &lt;li&gt;The application ticket is then sent to the application server, which verifies the
application ticket with the KDC.&lt;/li&gt;
  &lt;li&gt;Service ticket for the required Service is sent to the server.&lt;/li&gt;
  &lt;li&gt;Server sends the requested data to the client&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;advantages-of-kerberos&quot;&gt;Advantages of Kerberos&lt;/h2&gt;
&lt;p&gt;There are many advantages of Kerberos than traditional securing methodologies.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Scalable
    &lt;ul&gt;
      &lt;li&gt;Servers do not need to contact KDC to authenticate users&lt;/li&gt;
      &lt;li&gt;Only users and machine account authenticate with the KDC, once per 10h of activity&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Secure
    &lt;ul&gt;
      &lt;li&gt;Passwords are not transmitted over the wire&lt;/li&gt;
      &lt;li&gt;Ticket based authentication based on certificates trusts&lt;/li&gt;
      &lt;li&gt;Short-term session keys (Long-term secrets used only to derive short-term keys)&lt;/li&gt;
      &lt;li&gt;Separate session key for each user-server pair&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Advanced Features
    &lt;ul&gt;
      &lt;li&gt;Single Sign-On&lt;/li&gt;
      &lt;li&gt;Delegation&lt;/li&gt;
      &lt;li&gt;Cross Domain Authentication&lt;/li&gt;
      &lt;li&gt;Interoperability&lt;/li&gt;
      &lt;li&gt;Mutual authentication&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;kerberos-applications&quot;&gt;Kerberos Applications&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Local authentication
    &lt;ul&gt;
      &lt;li&gt;login and su in OpenBSD&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Authentication for network protocols
    &lt;ul&gt;
      &lt;li&gt;Remote login&lt;/li&gt;
      &lt;li&gt;Remote Shell&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Secure windowing systems&lt;/li&gt;
  &lt;li&gt;Microsoft Windows (used in Security Support Provider(SSP))&lt;/li&gt;
  &lt;li&gt;For Kerberizing applications such as Email, FTP, network file systems&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;weaknesses--limitations&quot;&gt;Weaknesses / Limitations&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Single point of failure
    &lt;ul&gt;
      &lt;li&gt;It requires continuous availability of a central Kerberos server. In a case of Knock out the Kerberos server and no one can log in&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Password guessing
    &lt;ul&gt;
      &lt;li&gt;no authentication is required to request a ticket, so attacker can gather equivalent of &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/passwd&lt;/code&gt; by requesting many tickets.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Kerberos is vulnerable if the local machine is compromised and malware captures the password.&lt;/li&gt;
  &lt;li&gt;Ticket hijacking – Malicious user may steal the service ticket of another user on the same workstation and try to use it&lt;/li&gt;
  &lt;li&gt;server authentication – Attacker may misconfigure the network so that he receives messages addressed to a legitimate server&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;Image Copyrights : www.freepik.com .&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;
</description>
				<pubDate>Thu, 01 Feb 2018 00:00:00 +0530</pubDate>
				<link>/security/2018/02/01/kerberos-simplified.html</link>
				<guid isPermaLink="true">/security/2018/02/01/kerberos-simplified.html</guid>
			</item>
		
			<item>
				<title>Sending POST requests from Node.js</title>
				<description>&lt;p&gt;Hello all of you! from this article we are going to explore how to send POST requests from a Node.js Application. Node application using here is very much simple &amp;amp; very easy to understand.
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;For the easy coding we are using &lt;a href=&quot;https://www.npmjs.com/package/request&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;requests&lt;/code&gt;&lt;/a&gt; npm package to send the requests. In &lt;code class=&quot;highlighter-rouge&quot;&gt;requests&lt;/code&gt; npm package you can find many easy http method implementations&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;request.get()&lt;/em&gt;: Defaults to method: “GET”.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;request.post()&lt;/em&gt;: Defaults to method: “POST”.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;request.put()&lt;/em&gt;: Defaults to method: “PUT”.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;request.patch()&lt;/em&gt;: Defaults to method: “PATCH”.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;request.del() / request.delete()&lt;/em&gt;: Defaults to method: “DELETE”.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;request.head()&lt;/em&gt;: Defaults to method: “HEAD”.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;request.options()&lt;/em&gt;: Defaults to method: “OPTIONS”.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&quot;so-lets-directly-go-into-the-code&quot;&gt;So lets directly go into the code&lt;/h3&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;http&lt;/span&gt;       &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;require&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'http'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;express&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;require&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'express'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;request&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;require&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'request'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;app&lt;/span&gt;        &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;express&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;http&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;createServer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;port&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;sr&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;Starting&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;server&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;server&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;listen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;console&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'Server Started on port '&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;sr&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;POST&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;request&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;post&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;s1&quot;&gt;'http://localhost:8090/api/users'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;ss&quot;&gt;json: &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;ss&quot;&gt;key1: &lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'value1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;ss&quot;&gt;key2: &lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'value2'&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;statusCode&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;console&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;to-run-the-code-snippet&quot;&gt;To run the code snippet&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Step 1&lt;/strong&gt; - run &lt;code class=&quot;highlighter-rouge&quot;&gt;npm init&lt;/code&gt; to initiate a command line questionnaire that will conclude with the creation of a package.json in the directory&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;npm init&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 2&lt;/strong&gt; - You first need to install related npm packages using &lt;code class=&quot;highlighter-rouge&quot;&gt;npm install &amp;lt;package-name&amp;gt;&lt;/code&gt; command&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;npm install body-parser
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;npm install express
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;npm install request&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 3&lt;/strong&gt; Run the js file&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;node file-name.js&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;
</description>
				<pubDate>Fri, 19 Jan 2018 00:00:00 +0530</pubDate>
				<link>/node.js/2018/01/19/Sending-POST-requests-from-nodejs.html</link>
				<guid isPermaLink="true">/node.js/2018/01/19/Sending-POST-requests-from-nodejs.html</guid>
			</item>
		
			<item>
				<title>Playing with GIT Branches</title>
				<description>&lt;p&gt;Once you clone a git repository from github, you may need to figure out what other branches really exist on the remote repository so you can &lt;code class=&quot;highlighter-rouge&quot;&gt;pull&lt;/code&gt; them down and &lt;code class=&quot;highlighter-rouge&quot;&gt;checkout&lt;/code&gt; them, &lt;code class=&quot;highlighter-rouge&quot;&gt;merge&lt;/code&gt; them into your local branches. It is not a hard task if you are using GitHub Desktop. But much better to know if you interacting with command line.&lt;br /&gt;
&lt;br /&gt;
For the sake of better understanding, lets look into an example of cloning a remote repository into your local machine.
&lt;br /&gt;&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;git clone https://github.com/OmalPerera/sample-project.git
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;sample-project&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;to-check-the-local-branches-in-your-repository&quot;&gt;To check the local branches in your repository&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;git branch

&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; master&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;to-list-all-existing-branches&quot;&gt;To list all existing Branches&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;git branch -av

&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; master                cc30c0f Initial commit
  remotes/origin/HEAD   -&amp;gt; origin/master
  remotes/origin/dev    cc30c0f Initial commit
  remotes/origin/master cc30c0f Initial commit&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;create-a-local-tracking-branch-in-order-to-work-on-it&quot;&gt;Create a local tracking branch in order to work on it&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;git checkout &amp;lt;dev&amp;gt;

  Branch dev &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;up to track remote branch dev from origin.
  Switched to a new branch &lt;span class=&quot;s1&quot;&gt;'dev'&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;fetching-all-remote-branches-at-once&quot;&gt;Fetching all remote branches at once&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;git pull --all&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Below I have explained the difference between &lt;code class=&quot;highlighter-rouge&quot;&gt;git pull&lt;/code&gt; &amp;amp; &lt;code class=&quot;highlighter-rouge&quot;&gt;git fetch&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;switching-between-branches&quot;&gt;Switching between branches&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;git checkout &amp;lt;branch&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;creating-a-new-tracking-branch-based-on-a-remote-branch&quot;&gt;Creating a new tracking branch based on a remote branch&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;git checkout --track &amp;lt;remote/branch&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;deleting-local-branch&quot;&gt;Deleting local branch&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;git branch -d &amp;lt;branch&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;h3 id=&quot;git-pull-vs-git-fetch&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git pull&lt;/code&gt; vs &lt;code class=&quot;highlighter-rouge&quot;&gt;git fetch&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h4 id=&quot;git-pull&quot;&gt;git pull&lt;/h4&gt;
&lt;p&gt;Git tries to automate your work for you. Since it is context sensitive, git will merge any pulled commits into the branch you are currently working in. pull automatically merges the commits without letting you review them first. You may run into frequent conflicts if you are mot managing your branches in a proper way.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h4 id=&quot;git-fetch&quot;&gt;git fetch&lt;/h4&gt;
&lt;p&gt;Git gathers any commits from the particular branch that do not exist in your current branch &amp;amp; saves them in your local repository. But it doesn’t merge them with your current branch. This is particularly useful if you need to keep your repository up to date, but are working on something that might break if you update your files.
&lt;br /&gt;
&lt;img src=&quot;https://i.imgur.com/w4sr7bp.png&quot; alt=&quot;pull vs fetch diagram&quot; style=&quot;width: 400px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;h3 id=&quot;explaining-downstream--upstream&quot;&gt;Explaining &lt;code class=&quot;highlighter-rouge&quot;&gt;Downstream&lt;/code&gt; &amp;amp; &lt;code class=&quot;highlighter-rouge&quot;&gt;UpStream&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;&lt;br /&gt;
In terms of source control, you’re &lt;code class=&quot;highlighter-rouge&quot;&gt;downstream&lt;/code&gt; when you copy (clone, checkout, etc) from a repository. Information flowed &lt;code class=&quot;highlighter-rouge&quot;&gt;downstream&lt;/code&gt; to you.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
When you make changes, you usually want to send them back &lt;code class=&quot;highlighter-rouge&quot;&gt;upstream&lt;/code&gt; so they make it into that repository so that everyone pulling from the same source is working with all the same changes.
&lt;a href=&quot;https://stackoverflow.com/questions/2739376/definition-of-downstream-and-upstream&quot;&gt;Source&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;
</description>
				<pubDate>Fri, 29 Dec 2017 00:00:00 +0530</pubDate>
				<link>/git/2017/12/29/Playing-with-GIT-Branches.html</link>
				<guid isPermaLink="true">/git/2017/12/29/Playing-with-GIT-Branches.html</guid>
			</item>
		
			<item>
				<title>Install Maven on Mac OSX</title>
				<description>&lt;p&gt;First of all lets check for Maven in your system, because some versions of OS X came with Apache Maven 3 built in installed.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;mvn -version&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;if you are getting a response as follows.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;Apache Maven 3.5.2 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;138edd61fd100ec658bfa2d307c43b76940a5d7d; 2017-10-18T13:28:13+05:30&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
Maven home: /usr/share/maven
Java version: 1.8.0_60, vendor: Oracle Corporation
Java home: /Library/Java/JavaVirtualMachines/jdk1.8.0_60.jdk/Contents/Home/jre
Default locale: en_US, platform encoding: UTF-8
OS name: &lt;span class=&quot;s2&quot;&gt;&quot;mac os x&quot;&lt;/span&gt;, version: &lt;span class=&quot;s2&quot;&gt;&quot;10.12.5&quot;&lt;/span&gt;, arch: &lt;span class=&quot;s2&quot;&gt;&quot;x86_64&quot;&lt;/span&gt;, family: &lt;span class=&quot;s2&quot;&gt;&quot;mac&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Congratulations!! you don’t want to install Maven, You already have it.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
But if you are getting a message like this, you can go ahead with the tutorial&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;-bash: mvn: &lt;span class=&quot;nb&quot;&gt;command &lt;/span&gt;not found&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;installing-maven&quot;&gt;Installing Maven&lt;/h2&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&quot;step-i---downloading-maven&quot;&gt;Step I - Downloading Maven&lt;/h3&gt;
&lt;p&gt;Download maven from &lt;a href=&quot;http://maven.apache.org/download.cgi&quot;&gt;maven.apache.org&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&quot;step-ii---extract-the-targz&quot;&gt;Step II - Extract the tar.gz&lt;/h3&gt;
&lt;p&gt;Navigate to the directory where &lt;code class=&quot;highlighter-rouge&quot;&gt;tar.gz&lt;/code&gt; file downloaded &amp;amp; extract it to &lt;code class=&quot;highlighter-rouge&quot;&gt;/usr/share/maven&lt;/code&gt;. You can use following terminal commands to exact directly in to &lt;code class=&quot;highlighter-rouge&quot;&gt;/usr/share/maven&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Remember to change the maven version in the command!.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;sudo tar -xvf apache-maven-3.5.2.tar.gz -C /usr/share/
&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /usr/share/
sudo mv apache-maven-3.5.2 maven&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&quot;step-iii---update-the-home--path-variables&quot;&gt;Step III - Update the HOME &amp;amp; PATH variables&lt;/h3&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;M2_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/usr/share/maven
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$PATH&lt;/span&gt;:&lt;span class=&quot;nv&quot;&gt;$M2_HOME&lt;/span&gt;/bin&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;hr /&gt;

&lt;p&gt;Okay! now check the previous command again&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;mvn -version&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;if you are getting a response as follows.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;Apache Maven 3.5.2 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;138edd61fd100ec658bfa2d307c43b76940a5d7d; 2017-10-18T13:28:13+05:30&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
Maven home: /usr/share/maven
Java version: 1.8.0_60, vendor: Oracle Corporation
Java home: /Library/Java/JavaVirtualMachines/jdk1.8.0_60.jdk/Contents/Home/jre
Default locale: en_US, platform encoding: UTF-8
OS name: &lt;span class=&quot;s2&quot;&gt;&quot;mac os x&quot;&lt;/span&gt;, version: &lt;span class=&quot;s2&quot;&gt;&quot;10.12.5&quot;&lt;/span&gt;, arch: &lt;span class=&quot;s2&quot;&gt;&quot;x86_64&quot;&lt;/span&gt;, family: &lt;span class=&quot;s2&quot;&gt;&quot;mac&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Congratulations! 🎉   you have correctly configured the Maven in your Mac!&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;
</description>
				<pubDate>Thu, 21 Dec 2017 00:00:00 +0530</pubDate>
				<link>/howto/2017/12/21/Install-Maven-on-Mac-OSX.html</link>
				<guid isPermaLink="true">/howto/2017/12/21/Install-Maven-on-Mac-OSX.html</guid>
			</item>
		
			<item>
				<title>Up & Run Apache Spark within seconds with all dependencies</title>
				<description>&lt;p&gt;&lt;a href=&quot;https://github.com/OmalPerera/install-Spark&quot;&gt;install-spark&lt;/a&gt; is a fully automated Spark installation bash script for linux Dabian based Servers.&lt;/p&gt;

&lt;p&gt;Script will install following key components needes to install Real-time data processing with few clicks.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Full Update &amp;amp; Upgrade&lt;/li&gt;
  &lt;li&gt;install up-to-date JRE&lt;/li&gt;
  &lt;li&gt;install up-to-date JDK&lt;/li&gt;
  &lt;li&gt;install scala 2.11.11&lt;/li&gt;
  &lt;li&gt;install Apache kafka 2.10 0.10.2.1&lt;/li&gt;
  &lt;li&gt;install git&lt;/li&gt;
  &lt;li&gt;install sbt&lt;/li&gt;
  &lt;li&gt;install Apache spark spark-2.2.0 pre-built for Apache hadoop 2.7 &amp;amp; later&lt;/li&gt;
  &lt;li&gt;all the environmental + all the PATH variables&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;using-the-script&quot;&gt;Using the Script&lt;/h1&gt;

&lt;h3 id=&quot;1-granting-the-executing-permission-to-the-script&quot;&gt;1. Granting the executing permission to the script&lt;/h3&gt;

&lt;p&gt;Navigate to the directory where the script is.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;chmod +x install-spark.sh&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h3 id=&quot;2-run-the-script&quot;&gt;2. Run the script&lt;/h3&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;source &lt;/span&gt;install-spark.sh&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;customizing-the-script&quot;&gt;Customizing the Script&lt;/h1&gt;

&lt;p&gt;In the script you can define the &lt;strong&gt;versions&lt;/strong&gt; of libraries that you need to install.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;eg: spark-2.2.0-bin-hadoop2.7 , scala-2.11.11&lt;/em&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Under the &lt;code class=&quot;highlighter-rouge&quot;&gt;# Default Application versions&lt;/code&gt; define your prefered version.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;c&quot;&gt;# Default Application versions&lt;/span&gt;

&lt;span class=&quot;nv&quot;&gt;SCALA_VERSION&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;scala-2.11.11&quot;&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;SPARK_VERSION&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;spark-2.2.0-bin-hadoop2.7&quot;&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;KAFKA_VERSION&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;kafka_2.10-0.10.2.1&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;
</description>
				<pubDate>Sat, 16 Dec 2017 00:00:00 +0530</pubDate>
				<link>/bigdata/2017/12/16/Install-Spark-within-seconds.html</link>
				<guid isPermaLink="true">/bigdata/2017/12/16/Install-Spark-within-seconds.html</guid>
			</item>
		
			<item>
				<title>Apache Spark - Kafka Integration for Real-time Data Processing with Scala</title>
				<description>&lt;p&gt;Real-time processing! kind of a trending term that techie people talks &amp;amp; do things. So actually what are the components do we need to perform Real-time Processing. Apache Spark Streaming, Apache Kafka are key two components out of many that comes in to my mind.&lt;/p&gt;

&lt;p&gt;Spark Streaming is built-in library in Apache Spark which is micro-batch oriented stream processing engine. There are other alternatives such as Flink, Storm etc.&lt;/p&gt;

&lt;p&gt;As we discussed in above paragraph, Spark Streaming reads &amp;amp; process streams. So who provides these Streams to Spark ?. In that case, we use Apache kafka to accomplish this task.&lt;/p&gt;

&lt;p&gt;But why? can’t we use Direct streams via TCP sockets?. But the point is &lt;em&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;parallelism&lt;/code&gt;&lt;/em&gt; . Kafka enables parallel streaming with a support named &lt;code class=&quot;highlighter-rouge&quot;&gt;&quot;partition&quot;&lt;/code&gt; which is highly compatible to use with Spark’s &lt;code class=&quot;highlighter-rouge&quot;&gt;&quot;partition&quot;&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;I think, now it is clear why are we using spark with kafka. So let’s look in to integrate these two components. Consider this as a starting point.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;my-development-environment&quot;&gt;My Development Environment&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Spark version 	- 2.2.0&lt;/li&gt;
  &lt;li&gt;Scala version	  - 2.11.11&lt;/li&gt;
  &lt;li&gt;SBT version 	  - 0.13.16&lt;/li&gt;
  &lt;li&gt;Kafka version 	- 0.10.2.0&lt;/li&gt;
  &lt;li&gt;OS 				      - Mac OS (Unix based)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As mentioned the Spark &lt;a href=&quot;https://spark.apache.org/docs/latest/index.html#downloading&quot;&gt;docs&lt;/a&gt;
“Spark runs on Java 8+, Python 2.7+/3.4+ and R 3.1+. For the Scala API, &lt;strong&gt;Spark 2.2.0 uses Scala 2.11. You will need to use a compatible Scala version (2.11.x)&lt;/strong&gt;.”
so you better use any 2.11.x version of scala in order to avoid dependency problems.&lt;/p&gt;

&lt;p&gt;Before continuing the project, probably you better double check your scala &amp;amp; sbt installations in your machine&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;scala -version
Scala code runner version 2.11.11 -- Copyright 2002-2017, LAMP/EPFL&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;sbt sbtVersion
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] Updated file /root/.../project/build.properties: &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;sbt.version to 0.13.16&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;developing-the-spark-app-with-scala&quot;&gt;Developing the Spark app with Scala&lt;/h1&gt;
&lt;p&gt;&lt;br /&gt;
&lt;strong&gt;Note&lt;/strong&gt; : Dependencies for this project can be definitely change with the time. And also basically those dependencies depend on the scala version, Spark version, SBT version etc that you have installed in your system. So try to stick with above mentioned development environment or else follow up the error log &amp;amp; adjust the dependencies according to your development environment.
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;So let’s start the journey to Real-time data processing with &lt;strong&gt;kafka&lt;/strong&gt; , &lt;strong&gt;spark&lt;/strong&gt; , &amp;amp; &lt;strong&gt;scala&lt;/strong&gt; !&lt;/p&gt;

&lt;h3 id=&quot;directory-structure&quot;&gt;Directory structure&lt;/h3&gt;

&lt;p&gt;first of all we have to arrange our project’s directories &amp;amp; files in to a specific order which supports for sbt. Folder structure should be as follows.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;./src
./src/main
./src/main/scala
./src/main/scala/kafkar.scala
./build.sbt&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;buildsbt-file&quot;&gt;build.sbt file&lt;/h3&gt;

&lt;p&gt;As we are doing our project with SBT, here is the sbt build file &lt;code class=&quot;highlighter-rouge&quot;&gt;build.sbt&lt;/code&gt; , where we include all the dependencies needed for our project.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;name :&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;kafkar&quot;&lt;/span&gt;

version :&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;0.1&quot;&lt;/span&gt;

scalaVersion :&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;2.11.11&quot;&lt;/span&gt;

retrieveManaged :&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true

&lt;/span&gt;fork :&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true

&lt;/span&gt;libraryDependencies +&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;org.apache.spark&quot;&lt;/span&gt; % &lt;span class=&quot;s2&quot;&gt;&quot;spark-streaming_2.11&quot;&lt;/span&gt; % &lt;span class=&quot;s2&quot;&gt;&quot;2.2.0&quot;&lt;/span&gt;

libraryDependencies +&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;org.apache.spark&quot;&lt;/span&gt; % &lt;span class=&quot;s2&quot;&gt;&quot;spark-streaming-kafka-0-8_2.11&quot;&lt;/span&gt; % &lt;span class=&quot;s2&quot;&gt;&quot;2.1.0&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;integrating-spark-streaming-and-apache-kafka&quot;&gt;Integrating Spark Streaming and Apache Kafka&lt;/h3&gt;

&lt;p&gt;Here we are going to fetch data from kafka topic to our spark app. if you are absolute newbie to these area, I’m recommending you to google on &lt;em&gt;what is kafka?, how it works, what are kafka topics? what spark does?&lt;/em&gt; . I’m leaving it to you as a homework.&lt;/p&gt;

&lt;p&gt;So this will be the code&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-js&quot; data-lang=&quot;js&quot;&gt;&lt;span class=&quot;kr&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;log4j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.{&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Level&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;Logger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;kr&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;SparkConf&lt;/span&gt;
&lt;span class=&quot;kr&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;streaming&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;kafka&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;KafkaUtils&lt;/span&gt;
&lt;span class=&quot;kr&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;streaming&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.{&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Seconds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;StreamingContext&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;


&lt;span class=&quot;nx&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;kafkar&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

  &lt;span class=&quot;nx&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;nx&quot;&gt;Logger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;getLogger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;org&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;setLevel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Level&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;OFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;Logger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;getLogger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;akka&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;setLevel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Level&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;OFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;nx&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;program started&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;nx&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;conf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;SparkConf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;setMaster&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;local[4]&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;setAppName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;kafkar&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;ssc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;StreamingContext&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;Seconds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;// my kafka topic name is 'test'&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;kafkaStream&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;KafkaUtils&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;createStream&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;ssc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;localhost:2181&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;spark-streaming-consumer-group&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;Map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;test&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;nx&quot;&gt;kafkaStream&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;ssc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;start&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;ssc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;awaitTermination&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;You would need a multi-core machine (&amp;gt;= 2 cores) for spark-streaming to work while running in standalone mode. But it will work fine if you run it in local mode with master as local[4].&lt;/p&gt;

&lt;p&gt;there are several Master Urls passed to Spark&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;local&lt;/strong&gt; - Run Spark locally with one worker thread (no parallelism at all).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;local[K]&lt;/strong&gt; -	Run Spark locally with K worker threads (ideally, set this to the number of cores on your machine).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;local[* ]&lt;/strong&gt;	- Run Spark locally with as many worker threads as logical cores on your machine.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;spark://HOST:PORT&lt;/strong&gt; - 	Connect to the given Spark standalone cluster master.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;are some of them&lt;/p&gt;

&lt;p&gt;so we are now done with the spark app. prior to run our app, we have to make sure we have Up &amp;amp; running kafka topic with name of &lt;code class=&quot;highlighter-rouge&quot;&gt;test&lt;/code&gt;. If not Spark app wont be able to consume the streams.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h1 id=&quot;configuring-up-kafka-broker&quot;&gt;Configuring up Kafka broker&lt;/h1&gt;

&lt;p&gt;If you don’t have kafka installed in your environment, you can refer my post &lt;a href=&quot;https://omalperera.github.io/general/bigdata/2017/11/10/Setting-Up-Apache-Kafka-localy.html&quot;&gt;Setting Up Apache Kafka locally&lt;/a&gt; to setup it from the scratch.
if you have already installed kafka, we have to create a topic named &lt;code class=&quot;highlighter-rouge&quot;&gt;test&lt;/code&gt; &amp;amp; start kafka producer.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;starting-the-zookeeper-server&quot;&gt;Starting the Zookeeper Server&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;As you are now in the &lt;code class=&quot;highlighter-rouge&quot;&gt;kafka_2.10-0.10.2.0&lt;/code&gt; directory (can be differ depends on your kafka version), execute the following command&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;  sudo bin/zookeeper-server-start.sh config/zookeeper.properties
  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;Starting the Kafka Server&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;  sudo bin/kafka-server-start.sh config/server.properties
  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;creating-topic&quot;&gt;Creating topic&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Creating a topic located at zookeeper at the &lt;code class=&quot;highlighter-rouge&quot;&gt;localhost:2181&lt;/code&gt; named &lt;code class=&quot;highlighter-rouge&quot;&gt;test&lt;/code&gt; with a &lt;code class=&quot;highlighter-rouge&quot;&gt;single partition&lt;/code&gt; &amp;amp; &lt;code class=&quot;highlighter-rouge&quot;&gt;single replica&lt;/code&gt;. (do it in a separate terminal).&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;  sudo bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic &lt;span class=&quot;nb&quot;&gt;test&lt;/span&gt;
  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;To ensure that our topic is created, execute following command&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;  bin/kafka-topics.sh --list --zookeeper localhost:2181
  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;running-the-producer&quot;&gt;Running the Producer&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;This is for feed the &lt;code class=&quot;highlighter-rouge&quot;&gt;test&lt;/code&gt; Topic (do it in a separate console)&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;  bin/kafka-console-producer.sh --broker-list localhost:9092 --topic &lt;span class=&quot;nb&quot;&gt;test&lt;/span&gt;
  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;You can send messages to the Kafka cluster from the console even except the standard file inputs. just type the message in the console. These messages will be consumed by our spark app.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;  This is a Sample message
  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;running-the-consumer&quot;&gt;Running the Consumer&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;This is for listen to the producer at that port (do it in a separate terminal).&lt;/li&gt;
  &lt;li&gt;Following command will listens for the topic inputs and outputs&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;    bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic &lt;span class=&quot;nb&quot;&gt;test&lt;/span&gt;
    &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;If you type messages into the producer terminal you should see them appear in the consumer terminal.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Now Kafka broker is ready to go. Now its time to run our Spark application.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h1 id=&quot;running-spark-application-with-sbt&quot;&gt;Running Spark Application with sbt&lt;/h1&gt;

&lt;p&gt;We are all set for running the application. So open a terminal window &amp;amp; navigate to the project directory. Now we just want to compile the code with &lt;code class=&quot;highlighter-rouge&quot;&gt;sbt compile&lt;/code&gt; &amp;amp; run it with &lt;code class=&quot;highlighter-rouge&quot;&gt;sbt run&lt;/code&gt; on sbt console.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;sbt compile

&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] Loading project definition from /root/xc/project
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] Loading settings from build.sbt ...
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] Set current project to kafkar &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;build file:/root/xc/&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] Executing &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;batch mode. For better performance use sbt&lt;span class=&quot;s1&quot;&gt;'s shell
[success] Total time: 6 s, completed Dec 1, 2017 12:36:52 PM&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;sbt run

&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] Loading project definition from /root/xc/project
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] Loading settings from build.sbt ...
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] Set current project to kafkar &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;build file:/root/xcity/&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] Running &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;fork&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; kafkar
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] program started
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] -------------------------------------------
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] Time: 1512131872000 ms
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] -------------------------------------------
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] -------------------------------------------
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] Time: 1512131873000 ms
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] -------------------------------------------
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] -------------------------------------------
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] Time: 1512131874000 ms
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] -------------------------------------------&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;We are done! Spark Streaming is now connected to Apache Kafka and consumes messages every 2 seconds. Leave it running and switch to kafka Producer terminal and enter some messages&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;gp&quot;&gt;omal@ubuntu-london:~/kafka_2.10-0.10.2.1# &lt;/span&gt;sudo bin/kafka-console-producer.sh --broker-list localhost:9092 --topic &lt;span class=&quot;nb&quot;&gt;test

&lt;/span&gt;OK,41,14,690,41,2014-11-13T09:15:00,3,32502142,158355
OK,36,19,690,36,2014-11-13T09:20:00,1,32502581,158355
OK,36,11,690,36,2014-11-13T09:25:00,0,32503023,158355&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Switch to the terminal with Spark application running and see the message printed out.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] -------------------------------------------
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] Time: 1512137948000 ms
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] -------------------------------------------
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] -------------------------------------------
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] Time: 1512137949000 ms
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] -------------------------------------------
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;null,OK,41,14,690,41,2014-11-13T09:15:00,3,32502142,158355&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;null,OK,36,19,690,36,2014-11-13T09:20:00,1,32502581,158355&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;null,OK,36,11,690,36,2014-11-13T09:25:00,0,32503023,158355&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] -------------------------------------------
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] Time: 1512137950000 ms
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] -------------------------------------------
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] -------------------------------------------
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] Time: 1512137951000 ms
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;info] -------------------------------------------&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Additionally you can visit Apache Spark web UI (most of the time http://localhost:4040/) to get more details, histograms on your Spark job.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;congratulations-----you-have-completed-the-mission&quot;&gt;Congratulations!  🎉   you have completed the mission&lt;/h4&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;
</description>
				<pubDate>Thu, 30 Nov 2017 00:00:00 +0530</pubDate>
				<link>/bigdata/2017/11/30/Real-time-Data-Processing-with-Apache-Kafka-Spark-Streaming-and-Scala.html</link>
				<guid isPermaLink="true">/bigdata/2017/11/30/Real-time-Data-Processing-with-Apache-Kafka-Spark-Streaming-and-Scala.html</guid>
			</item>
		
			<item>
				<title>Setting Up Apache Kafka locally</title>
				<description>&lt;p&gt;This Guide is for the linux based OS &amp;amp; directories in the Kafka setup can be slightly different in the windows setup.
Mainly we deal with the &lt;code class=&quot;highlighter-rouge&quot;&gt;/bin&lt;/code&gt; folder.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;for mac     - &lt;code class=&quot;highlighter-rouge&quot;&gt;kafka_2.10-0.10.2.0/bin/&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;for Windows - &lt;code class=&quot;highlighter-rouge&quot;&gt;kafka_2.10-0.10.2.0\bin\windows\&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; : Every command must be executed in a separate terminal or console except for creating the topic and ending a server.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;step-1---download-the-source-code--extract-it&quot;&gt;Step 1 - Download the source code &amp;amp; extract it&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Download Apache kafka from &lt;a href=&quot;https://www.apache.org/dyn/closer.cgi?path=/kafka/1.0.0/kafka_2.10-0.10.2.0.tgz&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Navigate to the downloaded directory &amp;amp; &lt;code class=&quot;highlighter-rouge&quot;&gt;untar&lt;/code&gt; the kafka_2.10-0.10.2.0.tar&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;  tar -xzf kafka_2.10-0.10.2.0.tgz
  &lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;kafka_2.10-0.10.2.0
  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;step-2---starting-the-server&quot;&gt;Step 2 - Starting the Server&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;You first need to start a ZooKeeper serve, since Kafka uses Zookeeper for the tasks such as Electing a controller, Topic configuration, ACLs &amp;amp; for many more.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;As you are now in the &lt;code class=&quot;highlighter-rouge&quot;&gt;kafka_2.10-0.10.2.0&lt;/code&gt; directory execute the following command&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;  bin/zookeeper-server-start.sh config/zookeeper.properties
  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;Starting the Kafka Server&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;  bin/kafka-server-start.sh config/server.properties
  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;step-3---creating-a-topic&quot;&gt;Step 3 - Creating a Topic&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Creating a topic located at zookeeper at the &lt;code class=&quot;highlighter-rouge&quot;&gt;localhost:2181&lt;/code&gt; named &lt;code class=&quot;highlighter-rouge&quot;&gt;mytopic&lt;/code&gt; with a &lt;code class=&quot;highlighter-rouge&quot;&gt;single partition&lt;/code&gt; &amp;amp; &lt;code class=&quot;highlighter-rouge&quot;&gt;single replica&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;  bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic mytopic
  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;To ensure that our topic is created, execute following command&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;  bin/kafka-topics.sh --list --zookeeper localhost:2181
  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;step-4---running-the-producer&quot;&gt;Step 4 - Running the Producer&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;This is for feed the &lt;code class=&quot;highlighter-rouge&quot;&gt;mytopic&lt;/code&gt; Topic (do it in a separate console)&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;  bin/kafka-console-producer.sh --broker-list localhost:9092 --topic mytopic
  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;You can send messages to the Kafka cluster from the console even except the standard file inputs. just  type the message in the console.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;  This is a Sample message
  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;step-5---running-the-consumer&quot;&gt;Step 5 - Running the Consumer&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;This is for listen to the producer at that port (do it in a separate terminal).&lt;/li&gt;
  &lt;li&gt;Following command will listens for the topic inputs and outputs&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;    bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic mytopic
    &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;If you type messages into the producer terminal you should see them appear in the consumer terminal.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;step-6---stopping-the-kafka-server&quot;&gt;Step 6 - Stopping the Kafka Server&lt;/h3&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;bin/kafka-server-stop.sh  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;step-7---stopping-the-zookeeper-server&quot;&gt;Step 7 - Stopping the Zookeeper Server&lt;/h3&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;bin/zookeeper-server-stop.sh&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

</description>
				<pubDate>Fri, 10 Nov 2017 00:00:00 +0530</pubDate>
				<link>/general/bigdata/2017/11/10/Setting-Up-Apache-Kafka-localy.html</link>
				<guid isPermaLink="true">/general/bigdata/2017/11/10/Setting-Up-Apache-Kafka-localy.html</guid>
			</item>
		
	</channel>
</rss>
